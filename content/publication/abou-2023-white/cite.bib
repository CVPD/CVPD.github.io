@article{abou2023white,
 abstract = {Deep learning (DL) has made significant advances in computer vision with the advent of vision transformers (ViTs). Unlike convolutional neural networks (CNNs), ViTs use self-attention to extract both local and global features from image data, and then apply residual connections to feed these features directly into a fully networked multilayer perceptron head. In hospitals, hematologists prepare peripheral blood smears (PBSs) and read them under a medical microscope to detect abnormalities in blood counts such as leukemia. However, this task is time-consuming and prone to human error. This study investigated the transfer learning process of the Google ViT and ImageNet CNNs to automate the reading of PBSs. The study used two online PBS datasets, PBC and BCCD, and transferred them into balanced datasets to investigate the influence of data amount and noise immunity on both neural networks. The PBC results showed that the Google ViT is an excellent DL neural solution for data scarcity. The BCCD results showed that the Google ViT is superior to ImageNet CNNs in dealing with unclean, noisy image data because it is able to extract both global and local features and use residual connections, despite the additional time and computational overhead.},
 author = {Abou Ali, Mohamad and Dornaika, Fadi and Arganda-Carreras, Ignacio},
 doi = {10.3390/a16110525},
 journal = {Algorithms},
 number = {11},
 pages = {525},
 publisher = {MDPI},
 title = {White blood cell classification: Convolutional Neural Network (CNN) and Vision Transformer (ViT) under medical microscope},
 volume = {16},
 year = {2023}
}
