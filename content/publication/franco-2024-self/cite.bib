@inproceedings{franco2024self,
 abstract = {Fluorescence microscopy plays a crucial role in cellular analysis but is often hindered by phototoxicity and limited spectral channels. Label-free transmitted light microscopy presents an attractive alternative, yet recovering fluorescence images from such inputs remains difficult. In this work, we address the Cell Painting problem within the LightMyCells challenge at the International Symposium on Biomedical Imaging (ISBI) 2024, aiming to predict optimally focused fluorescence images from label-free transmitted light inputs. Leveraging advancements self-supervised Vision Transformers, our method overcomes the constraints of scarce annotated biomedical data and fluorescence microscopy’s drawbacks. Four specialized models, each targeting a different organelle, are pretrained in a self-supervised manner to enhance model generalization. Our method, integrated within the open-source BiaPy library, contributes to the advancement of image-to-image deep-learning techniques in cellular analysis, offering a promising solution for robust and accurate fluorescence image prediction from label-free transmitted light inputs. Code and documentation can be found at https://github.com/danifranco/BiaPy and a custom tutorial to reproduce all results is available at https://biapy.readthedocs.io/en/latest/tutorials/image-to-image/lightmycells.html.},
 author = {Franco-Barranco, Daniel and González-Marfil, Aitor and Arganda-Carreras, Ignacio},
 booktitle = {2024 IEEE International Symposium on Biomedical Imaging (ISBI)},
 doi = {10.1109/ISBI56570.2024.10635818},
 organization = {IEEE},
 pages = {1--5},
 title = {Self-supervised Vision Transformers for image-to-image labeling: a BiaPy solution to the LightMyCells Challenge},
 year = {2024}
}
