@article{slika2025pvitgatt,
 abstract = {The development of a robust and adaptive deep learning technique for the diagnosis of pneumonia and the assessment of its severity was a major challenge. Indeed, both chest X-rays (CXR) and CT scans have been widely studied for the diagnosis, detection and quantification of pneumonia. In this paper, a novel approach (PViTGAtt-IP) based on a parallel array of vision transformers is presented, in which the input image is divided into regions of interest. Each region is fed into an individual model and the collective output gives the severity score. Three parallel architectures were also derived and tested. The proposed models were subjected to rigorous tests on two different datasets: RALO CXRs and Per COVID-19 CT scans. The experimental results showed that the proposed models exhibited high performance in accurately predicting scores for both datasets. In particular, the parallel transformers with multi-gate attention proved to be the best performing model. Furthermore, a comparative analysis using state-of-the-art methods showed that our proposed approach consistently achieved competitive or even better performance in terms of the Mean Absolute Error (MAE) and the Pearson Correlation Coefficient (PC). This emphasizes the effectiveness and superiority of our models in the context of diagnosing and assessing the severity of pneumonia. The source codes used in our study are publicly available and can be found at https://github.com/bouthainas/PViTGAtt-IP.},
 author = {Slika, Bouthaina and Dornaika, Fadi and Bougourzi, Fares and Hammoudi, Karim},
 doi = {10.1109/TBDATA.2025.3556612},
 issn = {2332-7790},
 journal = {IEEE Transactions on Big Data},
 number = {},
 pages = {1-13},
 title = {PViTGAtt-IP: Severity Quantification of Lung Infections in Chest X-rays and CT Scans via Parallel and Cross-Attended Encoders},
 volume = {},
 year = {2025}
}
