@INPROCEEDINGS{bekhouche2025ECTE_Tech,
	author={Rahmani, Chahrazad and Benlamoudi, Azeddine and Bekhouche, Salah Eddine and Bounab, Yazid and Samai, Djamel and Dornaika, Fadi},
	booktitle={2024 1st International Conference on Electrical, Computer, Telecommunication and Energy Technologies (ECTE-Tech)}, 
	title={Advancing Road Safety: A CNN-Based Semi-Supervised Learning Approach for Drivers' Drowsiness Detection}, 
	year={2024},
	volume={},
	number={},
	pages={1-6},
	abstract={The National Safety Council (NSC) has reported that each year, driver fatigue is responsible for 100,000 accidents, 71,000 injuries, and 1,550 fatalities, often manifesting as drowsiness. Most current systems fail to anticipate accidents beforehand, focusing primarily on external factors. This paper introduces a novel drowsiness detection framework aimed at reducing accidents caused by drivers dozing off behind the wheel and minimizing harm to individuals engaged in prolonged computer use. The proposed method leverages a Convolutional Neural Network (CNN) with a semi-supervised learning technique, setting it apart from existing approaches. The effectiveness of our approach is evaluated using the UTA-RLDD video dataset, and the results demonstrate that the proposed method outperforms state-of-the-art methods, achieving 99.98% accuracy.},
	keywords={Accuracy;Wheels;Semisupervised learning;Fatigue;Robustness;Safety;Convolutional neural networks;Vehicles;Accidents;Testing;Fatigue;drowsiness detection;CNN;semi-supervised learning},
	doi={10.1109/ECTE-Tech62477.2024.10850976},
	ISSN={},
	month={Dec},
}


@Article{bekhouche2024Electronics,
	AUTHOR = {Bekhouche, Salah Eddine and Benlamoudi, Azeddine and Dornaika, Fadi and Telli, Hichem and Bounab, Yazid},
	TITLE = {Facial Age Estimation Using Multi-Stage Deep Neural Networks},
	JOURNAL = {Electronics},
	VOLUME = {13},
	YEAR = {2024},
	NUMBER = {16},
	ARTICLE-NUMBER = {3259},
	URL = {https://www.mdpi.com/2079-9292/13/16/3259},
	ISSN = {2079-9292},
	ABSTRACT = {Over the last decade, the world has witnessed many breakthroughs in artificial intelligence, largely due to advances in deep learning technology. Notably, computer vision solutions have significantly contributed to these achievements. Human face analysis, a core area of computer vision, has gained considerable attention due to its wide applicability in fields such as law enforcement, social media, and marketing. However, existing methods for facial age estimation often struggle with accuracy due to limited feature extraction capabilities and inefficiencies in learning hierarchical representations. This paper introduces a novel framework to address these issues by proposing a Multi-Stage Deep Neural Network (MSDNN) architecture. The MSDNN architecture divides each CNN backbone into multiple stages, enabling more comprehensive feature extraction, thereby improving the accuracy of age predictions from facial images. Our framework demonstrates a significant performance improvement over traditional solutions, with its effectiveness validated through comparisons with the EfficientNet and MobileNetV3 architectures. The proposed MSDNN architecture achieves a notable decrease in Mean Absolute Error (MAE) across three widely used public datasets (MORPH2, CACD, and AFAD) while maintaining a virtually identical parameter count compared to the initial backbone architectures. These results underscore the effectiveness and feasibility of our methodology in advancing the field of age estimation, showcasing it as a robust solution for enhancing the accuracy of age prediction algorithms.},
	DOI = {10.3390/electronics13163259}
}


@article{bekhouche2022KBS,
	title = {Driver drowsiness detection in video sequences using hybrid selection of deep features},
	journal = {Knowledge-Based Systems},
	volume = {252},
	pages = {109436},
	year = {2022},
	issn = {0950-7051},
	doi = {https://doi.org/10.1016/j.knosys.2022.109436},
	url = {https://www.sciencedirect.com/science/article/pii/S0950705122007225},
	author = {Salah Eddine Bekhouche and Yassine Ruichek and Fadi Dornaika},
	keywords = {Drowsiness detection, Transfer learning, Feature selection, SVM classifier},
	abstract = {Monitoring driver's drowsiness is a complex problem that involves many indicators whether behavioral or physiological. Drowsiness is a challenging problem that can lead to road disasters. Sleeping driver is more dangerous on the road than a speeding driver. Many statistics showed that one-fifth of road accidents in the world were due to driver fatigue, hence safety modules that can alert drowsy drivers in the hopes of reducing the risk of accidents are very important. This paper proposes a framework for driver drowsiness detection based on a computer vision solution. The proposed framework's first task is to detect the driver's face. A transfer learning is then performed for extracting the deep features from the driver's face image using a pre-trained deep convolutional network model trained on a facial recognition dataset. The previous tasks are applied in a sliding temporal window (less than a second) in which the frames are sampled. In this work, 9 frames were the best choice. The extracted features of these frames represent the observation matrix. Then temporal feature aggregation is applied to construct the raw feature vector. To obtain the final feature vector, a proposed feature selection is applied to omit possible irrelevant features. The final feature vector is finally fed to a binary classifier to decide whether there is drowsiness or not. Extensive experiments are applied to NTHU Drowsy Driver Detection (NTHU-DDD) video dataset. The outcomes show the outperformance of the proposed approach compared with the state-of-the-art approaches.}
}

@article{bekhouche2022NN,
	title = {Spatiotemporal CNN with Pyramid Bottleneck Blocks: Application to eye blinking detection},
	journal = {Neural Networks},
	volume = {152},
	pages = {150-159},
	year = {2022},
	issn = {0893-6080},
	doi = {https://doi.org/10.1016/j.neunet.2022.04.010},
	url = {https://www.sciencedirect.com/science/article/pii/S0893608022001423},
	author = {Salah Eddine Bekhouche and Ibrahim Kajo and Yassine Ruichek and Fadi Dornaika},
	keywords = {Eye blinking, Pyramid Bottleneck Blocks, Spatiotemporal CNN, Incremental SVD, Facial landmarks},
	abstract = {Eye blink detection is a challenging problem that many researchers are working on because it has the potential to solve many facial analysis tasks, such as face anti-spoofing, driver drowsiness detection, and some health disorders. There have been few attempts to detect blinking in the wild scenario, while most of the work has been done under controlled conditions. Moreover, current learning approaches are designed to process sequences that contain only a single blink ignoring the case of the presence of multiple eye blinks. In this work, we propose a fast framework for eye blink detection and eye blink verification that can effectively extract multiple blinks from image sequences considering several challenges such as lighting changes, variety of poses, and change in appearance. The proposed framework employs fast landmarks detector to extract multiple facial key points including the ones that identify the eye regions. Then, an SVD-based method is proposed to extract the potential eye blinks in a moving time window that is updated with new images every second. Finally, the detected blink candidates are verified using a 2D Pyramidal Bottleneck Block Network (PBBN). We also propose an alternative approach that uses a sequence of frames instead of an image as input and employs a continuous 3D PBBN that follows most of the state-of-the-art approaches schemes. Experimental results show the better performance of the proposed approach compared to the state-of-the-art approaches.}
}


@article{telli2021anovel,
	title={A novel multi-level pyramid co-variance operators for estimation of personality traits and job screening scores},
	author={Telli, Hichem and Sbaa, Salim and Bekhouche, Salah Eddine and Dornaika, Fadi and Taleb-Ahmed, Abdelmalik and L{\'o}pez, Miguel Bordallo},
	journal={Traitement du Signal},
	volume={38},
	number={3},
	pages={539--546},
	year={2021},
	doi="10.1007/978-3-030-14647-4_3",
	url="https://www.iieta.org/journals/ts/paper/10.18280/ts.380301",
	keywords = {APA2016 dataset, Big-Five personality traits, job candidate screening, PML-COV descriptor, regression},
	abstract = {Recently, automatic personality analysis is becoming an interesting topic for computer vision. Many attempts have been proposed to solve this problem using time-based sequence information. In this paper, we present a new framework for estimating the Big-Five personality traits and job candidate screening variable from video sequences. The framework consists of two parts: (1) the use of Pyramid Multi-level (PML) to extract raw facial textures at different scales and levels; (2) the extension of the Covariance Descriptor (COV) to fuse different local texture features of the face image such as Local Binary Patterns (LBP), Local Directional Pattern (LDP), Binarized Statistical Image Features (BSIF), and Local Phase Quantization (LPQ). Therefore, the COV descriptor uses the textures of PML face parts to generate rich low-level face features that are encoded using concatenation of all PML blocks in a feature vector. Finally, the entire video sequence is represented by aggregating these frame vectors and extracting the most relevant features. The exploratory results on the ChaLearn LAP APA2016 dataset compare well with state-of-the-art methods including deep learning-based methods.}

}

@article{bekhouche2020MTAP,
	title={A comparative study of human facial age estimation: handcrafted features vs. deep features},
	author={Bekhouche, Salah Eddine and Dornaika, Fadi and Benlamoudi, Azeddine and Ouafi, Abdelkrim and Taleb-Ahmed, Abdelmalik},
	journal={Multimedia Tools and Applications},
	volume={79},
	number={35},
	pages={26605--26622},
	year={2020},
	doi = {10.1007/s11042-020-09278-7},
	url = {https://link.springer.com/article/10.1007/s11042-020-09278-7},
	publisher={Springer},
	keywords = {Age estimation, Handcrafted features, Deep features, Support vector regression},
	abstract = {In recent times, the topic of human facial age estimation attracted much attention. This is due to its ability to improve biometrics systems. Recently, several applications that are based on the demographic attributes estimation have been developed. These include law enforcement, re-identification in videos, planed marketing, intelligent advertising, social media, and human-computer interaction. The main contributions of the paper are as follows. Firstly, it extends some handcrafted models that are based on the Pyramid Multi Level (PML) face representation. Secondly, it evaluates the performance of two different kinds of features that are handcrafted and deep features. It compares handcrafted and deep features in terms of accuracy and computational complexity. The proposed scheme of study includes the following three main steps: 1) face preprocessing; 2) feature extraction (two different kinds of features are studied: handcrafted and deep features); 3) feeding the obtained features to a linear regressor. In addition, we investigate the strengths and weaknesses of handcrafted and deep features when used in facial age estimation. Experiments are run on three public databases (FG-NET, PAL and FACES). These experiments show that both handcrafted and deep features are effective for facial age estimation.}
}


@article{bekhouche2017ESWA,
	title = {Pyramid multi-level features for facial demographic estimation},
	journal = {Expert Systems with Applications},
	volume = {80},
	pages = {297-310},
	year = {2017},
	issn = {0957-4174},
	doi = {10.1016/j.eswa.2017.03.030},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417417301793},
	author = {Salah Eddine Bekhouche and Abdelkrim Ouafi and Fadi Dornaika and Abdelmalik A. Taleb-Ahmed and Abdenour Hadid},
	keywords = {Demographic estimation, Classification, Age, Gender, Ethnicity},
	abstract = {We present a novel learning system for human demographic estimation in which the ethnicity, gender and age attributes are estimated from facial images. The proposed approach consists of the following three main stages: 1) face alignment and preprocessing; 2) constructing a Pyramid Multi-Level face representation from which the local features are extracted from the blocks of the whole pyramid; 3) feeding the obtained features to an hierarchical estimator having three layers. Due to the fact that ethnicity is by far the easiest attribute to estimate, the adopted hierarchy is as follows. The first layer predicts ethnicity of the input face. Based on that prediction, the second layer estimates the gender using the corresponding gender classifier. Based on the predicted ethnicity and gender, the age is finally estimated using the corresponding regressor. Experiments are conducted on five public databases (MORPH II, PAL, IoG, LFW and FERET) and another two challenge databases (Apparent age; Smile and Gender) of the 2016 ChaLearn Looking at People and Faces of the World Challenge and Workshop. These experiments show stable and good results. We present many comparisons against state-of-the-art methods. We also provide a study about cross-database evaluation. We quantitatively measure the performance drop in age estimation and in gender classification when the ethnicity attribute is misclassified.}
}

@InProceedings{bekhouche2017CVPR_Workshops,
	author={Bekhouche, Salah Eddine and Dornaika, Fadi and Ouafi, Abdelkrim and Taleb-Ahmed, Abdelmalik},
	booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, 
	title={Personality Traits and Job Candidate Screening via Analyzing Facial Videos}, 
	year={2017},
	volume={},
	number={},
	pages={1660-1663},
	abstract={In this paper, we propose a novel approach for estimating the Big Five personality traits and the job candidate screening attribute through facial videos. At running time, the proposed system feeds the Pyramid Multi-Level (PML) texture features extracted from the whole video sequence to 5 Support Vector Regressors in order to estimate the personality traits. These estimated five scores are then considered as new input features to the interview score regressor. The latter is given by a Gaussian Process Regression (GPR). The experimental results on ChaLearn LAP APA2016 dataset achieve good performance. Furthermore, they demonstrate that the computational cost of both the training and the testing of the proposed framework are very competitive in terms of accuracy and computational cost.},
	keywords={Videos;Interviews;Face;Feature extraction;Estimation;Video sequences;Ground penetrating radar},
	doi={10.1109/CVPRW.2017.211},
	ISSN={2160-7516},
	month={July},
}

@INPROCEEDINGS{boulkenafet2017acompetition,
  author={Zinelabdine Boulkenafet and Jukka Komulainen and Zahid Akhtar and Azeddine Benlamoudi and Djamel Samai and Salah Eddine Bekhouche and Abdelkrim Ouafi and Fadi Dornaika and Abdelmalik Taleb-Ahmed and Le Qin and Fei Peng and L. B. Zhang and Min Long and Shruti Bhilare and Vivek Kanhangad and Artur Costa-Pazo and Esteban Vázquez-Fernández and Daniel Pérez-Cabo and J. J. Moreira-Perez and Daniel González-Jiménez and Amir Mohammadi and Sushil Bhattacharjee and Sébastien Marcel and Svetlana Volkova and Y. Tang and N. Abe and L. Li and X. Feng and Z. Xia and X. Jiang and S. Liu and Rui Shao and Pong C. Yuen and Waldir R. de Almeida and Fernanda A. Andaló and Rafael Padilha and Gabriel Bertocco and William Dias and Jacques Wainer and Ricardo da Silva Torres and Anderson Rocha and Marcus A. Angeloni and Guilherme Folego and Alan Godoy and Abdenour Hadid},
  booktitle={2017 IEEE International Joint Conference on Biometrics (IJCB)}, 
  title={A competition on generalized software-based face presentation attack detection in mobile scenarios}, 
  year={2017},
  volume={},
  number={},
  pages={688-696},
  abstract={In recent years, software-based face presentation attack detection (PAD) methods have seen a great progress. However, most existing schemes are not able to generalize well in more realistic conditions. The objective of this competition is to evaluate and compare the generalization performances of mobile face PAD techniques under some real-world variations, including unseen input sensors, presentation attack instruments (PAI) and illumination conditions, on a larger scale OULU-NPU dataset using its standard evaluation protocols and metrics. Thirteen teams from academic and industrial institutions across the world participated in this competition. This time typical liveness detection based on physiological signs of life was totally discarded. Instead, every submitted system relies practically on some sort of feature representation extracted from the face and/or background regions using hand-crafted, learned or hybrid descriptors. Interesting results and findings are presented and discussed in this paper.},
  keywords={Face;Videos;Protocols;Printers;Feature extraction;Image color analysis;Databases},
  doi={10.1109/BTAS.2017.8272758},
  ISSN={2474-9699},
  month={Oct},
}
