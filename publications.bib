@article{lauenburg2023cyclic,
  author={Lauenburg, Leander and Lin, Zudi and Zhang, Ruihan and Santos, Márcia dos and Huang, Siyu and Arganda-Carreras, Ignacio and Boyden, Edward S. and Pfister, Hanspeter and Wei, Donglai},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={3D Domain Adaptive Instance Segmentation Via Cyclic Segmentation GANs}, 
  year={2023},
  quartile={Q1},
  factor2020={7.7},
  volume={27},
  number={8},
  pages={4018-4027},
  doi={10.1109/JBHI.2023.3281332}
}

@article{sanisidro2023folded,
  title={Folded: A toolkit to describe mammalian herbivore dentition from 2D images},
  author={Sanisidro, Oscar and Arganda-Carreras, Ignacio and Cantalapiedra, Juan L},
  journal={Methods in Ecology and Evolution},
  volume={14},
  number={2},
  pages={556--568},
  year={2023},
  quartile={Q1},
  factor2020={6.6},
  publisher={Wiley Online Library},
  doi={10.1111/2041-210X.14042}
}

@incollection{gomez2022building,
  title={Building a Bioimage Analysis Workflow Using Deep Learning},
  author={G{\'o}mez-de-Mariscal, Estibaliz and Franco-Barranco, Daniel and Mu{\~n}oz-Barrutia, Arrate and Arganda-Carreras, Ignacio},
  booktitle={Bioimage Data Analysis Workflows--Advanced Components and Methods},
  pages={59--88},
  year={2022},
  publisher={Springer International Publishing Cham},
  doi={10.1007/978-3-030-76394-7_4}
}

@article{gomez2022quantitative,
  title={A quantitative biophysical principle to explain the 3D cellular connectivity in curved epithelia},
  author={G{\'o}mez-G{\'a}lvez, Pedro and Vicente-Munuera, Pablo and Anbari, Samira and Tagua, Antonio and Gordillo-V{\'a}zquez, Carmen and Andr{\'e}s-San Rom{\'a}n, Jes{\'u}s A and Franco-Barranco, Daniel and Palacios, Ana M and Velasco, Antonio and Capit{\'a}n-Agudo, Carlos and Grima, Clara and Annese, Valentina and Arganda-Carreras, Ignacio and Robles, Rafael and M{\'a}rquez, Alberto and Buceta, Javier and Escudero, Luis M},
  journal={Cell Systems},
  volume={13},
  number={8},
  pages={631--643},
  year={2022},
  quartile={Q1},
  factor={9.3},
  doi={10.1016/j.cels.2022.06.003},
  publisher={Elsevier}
}

@article{franco2022domain,
  title = {Deep learning based domain adaptation for mitochondria segmentation on EM volumes},
  journal = {Computer Methods and Programs in Biomedicine},
  volume = {222},
  pages = {106949},
  year = {2022},
  quartile={Q1},
  factor={6.1},
  issn = {0169-2607},
  doi = {https://doi.org/10.1016/j.cmpb.2022.106949},
  url = {https://www.sciencedirect.com/science/article/pii/S0169260722003315},
  author = {Daniel Franco-Barranco and Julio Pastor-Tronch and Aitor González-Marfil and Arrate Muñoz-Barrutia and Ignacio Arganda-Carreras},
  abstract = {Background and Objective: Accurate segmentation of electron microscopy (EM) volumes of the brain is essential to characterize neuronal structures at a cell or organelle level. While supervised deep learning methods have led to major breakthroughs in that direction during the past years, they usually require large amounts of annotated data to be trained, and perform poorly on other data acquired under similar experimental and imaging conditions. This is a problem known as domain adaptation, since models that learned from a sample distribution (or source domain) struggle to maintain their performance on samples extracted from a different distribution or target domain. In this work, we address the complex case of deep learning based domain adaptation for mitochondria segmentation across EM datasets from different tissues and species. Methods: We present three unsupervised domain adaptation strategies to improve mitochondria segmentation in the target domain based on (1) state-of-the-art style transfer between images of both domains; (2) self-supervised learning to pre-train a model using unlabeled source and target images, and then fine-tune it only with the source labels; and (3) multi-task neural network architectures trained end-to-end with both labeled and unlabeled images. Additionally, to ensure good generalization in our models, we propose a new training stopping criterion based on morphological priors obtained exclusively in the source domain. The code and its documentation are publicly available at https://github.com/danifranco/EM_domain_adaptation. Results: We carried out all possible cross-dataset experiments using three publicly available EM datasets. We evaluated our proposed strategies and those of others based on the mitochondria semantic labels predicted on the target datasets. Conclusions: The methods introduced here outperform the baseline methods and compare favorably to the state of the art. In the absence of validation labels, monitoring our proposed morphology-based metric is an intuitive and effective way to stop the training process and select in average optimal models.}
}

@article{chourrout2022image,
  author = {Matthieu Chourrout and Margaux Roux and Carlie Boisvert and Coralie Gislard and David Legland and Ignacio Arganda-Carreras and C\'{e}cile Olivier and Fran\c{c}oise Peyrin and Herv\'{e} Boutin and Nicolas Rama and Thierry Baron and David Meyronet and Emmanuel Brun and Hugo Rositi and Marl\`{e}ne Wiart and Fabien Chauveau},
  journal = {Biomed. Opt. Express},
  keywords = {Image processing; Image quality; Refractive index; Shape analysis; Spatial resolution; Synchrotron radiation},
  number = {3},
  pages = {1640--1653},
  publisher = {Optica Publishing Group},
  title = {Brain virtual histology with X-ray phase-contrast tomography Part II: 3D morphologies of amyloid-$\beta$ plaques in Alzheimer's disease models},
  volume = {13},
  month = {Mar},
  year = {2022},
  quartile = {Q2},
  factor = {3.4}, 
  url = {https://opg.optica.org/boe/abstract.cfm?URI=boe-13-3-1640},
  doi = {10.1364/BOE.438890},
  abstract = {While numerous transgenic mouse strains have been produced to model the formation of amyloid-$\beta$ (A$\beta$) plaques in the brain, efficient methods for whole-brain 3D analysis of A$\beta$ deposits have to be validated and standardized. Moreover, routine immunohistochemistry performed on brain slices precludes any shape analysis of A$\beta$ plaques, or require complex procedures for serial acquisition and reconstruction. The present study shows how in-line (propagation-based) X-ray phase-contrast tomography (XPCT) combined with ethanol-induced brain sample dehydration enables hippocampus-wide detection and morphometric analysis of A$\beta$ plaques. Performed in three distinct Alzheimer mouse strains, the proposed workflow identified differences in signal intensity and 3D shape parameters: 3xTg displayed a different type of A$\beta$ plaques, with a larger volume and area, greater elongation, flatness and mean breadth, and more intense average signal than J20 and APP/PS1. As a label-free non-destructive technique, XPCT can be combined with standard immunohistochemistry. XPCT virtual histology could thus become instrumental in quantifying the 3D spreading and the morphological impact of seeding when studying prion-like properties of A$\beta$ aggregates in animal models of Alzheimer's disease. This is Part II of a series of two articles reporting the value of in-line XPCT for virtual histology of the brain; Part I shows how in-line XPCT enables 3D myelin mapping in the whole rodent brain and in human autopsy brain tissue.},
}

@article{almeida2022comparative,
  AUTHOR = {Almeida, Aitor and Bermejo, Unai and Bilbao, Aritz and Azkune, Gorka and Aguilera, Unai and Emaldi, Mikel and Dornaika, Fadi and Arganda-Carreras, Ignacio},
  TITLE = {A Comparative Analysis of Human Behavior Prediction Approaches in Intelligent Environments},
  JOURNAL = {Sensors},
  VOLUME = {22},
  YEAR = {2022},
  quartile={Q2},
  factor={3.9},
  NUMBER = {3},
  ARTICLE-NUMBER = {701},
  URL = {https://www.mdpi.com/1424-8220/22/3/701},
  PubMedID = {35161448},
  ISSN = {1424-8220},
  ABSTRACT = {Behavior modeling has multiple applications in the intelligent environment domain. It has been used in different tasks, such as the stratification of different pathologies, prediction of the user actions and activities, or modeling the energy usage. Specifically, behavior prediction can be used to forecast the future evolution of the users and to identify those behaviors that deviate from the expected conduct. In this paper, we propose the use of embeddings to represent the user actions, and study and compare several behavior prediction approaches. We test multiple model (LSTM, CNNs, GCNs, and transformers) architectures to ascertain the best approach to using embeddings for behavior modeling and also evaluate multiple embedding retrofitting approaches. To do so, we use the Kasteren dataset for intelligent environments, which is one of the most widely used datasets in the areas of activity recognition and behavior modeling.},
DOI = {10.3390/s22030701}
}

@article{nunez2022ego,
  title = {Egocentric Vision-based Action Recognition: A survey},
  journal = {Neurocomputing},
  volume = {472},
  pages = {175-197},
  year = {2022},
  quartile={Q2},
  factor={6.0},
  issn = {0925-2312},
  doi = {https://doi.org/10.1016/j.neucom.2021.11.081},
  url = {https://www.sciencedirect.com/science/article/pii/S0925231221017586},
author = {Adrián Núñez-Marcos and Gorka Azkune and Ignacio Arganda-Carreras},
keywords = {Deep learning, Computer vision, Human action recognition, Egocentric vision, Few-shot learning},
abstract = {The egocentric action recognition EAR field has recently increased its popularity due to the affordable and lightweight wearable cameras available nowadays such as GoPro and similars. Therefore, the amount of egocentric data generated has increased, triggering the interest in the understanding of egocentric videos. More specifically, the recognition of actions in egocentric videos has gained popularity due to the challenge that it poses: the wild movement of the camera and the lack of context make it hard to recognise actions with a performance similar to that of third-person vision solutions. This has ignited the research interest on the field and, nowadays, many public datasets and competitions can be found in both the machine learning and the computer vision communities. In this survey, we aim to analyse the literature on egocentric vision methods and algorithms. For that, we propose a taxonomy to divide the literature into various categories with subcategories, contributing a more fine-grained classification of the available methods. We also provide a review of the zero-shot approaches used by the EAR community, a methodology that could help to transfer EAR algorithms to real-world applications. Finally, we summarise the datasets used by researchers in the literature.}
}

@article{arganda2022statistical,
  AUTHOR={Arganda, Sara and Arganda-Carreras, Ignacio and Gordon, Darcy G. and Hoadley, Andrew P. and Pérez-Escudero, Alfonso and Giurfa, Martin and Traniello, James F. A.},   
  TITLE={Statistical Atlases and Automatic Labeling Strategies to Accelerate the Analysis of Social Insect Brain Evolution},      
  JOURNAL={Frontiers in Ecology and Evolution},      	
  VOLUME={9},           	
  YEAR={2022},
  factor={3.0},
  quartile={Q2},
  URL={https://www.frontiersin.org/articles/10.3389/fevo.2021.745707},       	
  DOI={10.3389/fevo.2021.745707},      	
  ISSN={2296-701X},    
  ABSTRACT={Current methods used to quantify brain size and compartmental scaling relationships in studies of social insect brain evolution involve manual annotations of images from histological samples, confocal microscopy or other sources. This process is susceptible to human bias and error and requires time-consuming effort by expert annotators. Standardized brain atlases, constructed through 3D registration and automatic segmentation, surmount these issues while increasing throughput to robustly sample diverse morphological and behavioral phenotypes. Here we design and evaluate three strategies to construct statistical brain atlases, or templates, using ants as a model taxon. The first technique creates a template by registering multiple brains of the same species. Brain regions are manually annotated on the template, and the labels are transformed back to each individual brain to obtain an automatic annotation, or to any other brain aligned with the template. The second strategy also creates a template from multiple brain images but obtains labels as a consensus from multiple manual annotations of individual brains comprising the template. The third technique is based on a template comprising brains from multiple species and the consensus of their labels. We used volume similarity as a metric to evaluate the automatic segmentation produced by each method against the inter- and intra-individual variability of human expert annotators. We found that automatic and manual methods are equivalent in volume accuracy, making the template technique an extraordinary tool to accelerate data collection and reduce human bias in the study of the evolutionary neurobiology of ants and other insects.}
}

@article{franco2022stable,
  title={Stable deep neural network architectures for mitochondria segmentation on electron microscopy volumes},
  author={Franco-Barranco, Daniel and Mu{\~n}oz-Barrutia, Arrate and Arganda-Carreras, Ignacio},
  journal={Neuroinformatics},
  volume={20},
  number={2},
  pages={437--450},
  year={2022},
  publisher={Springer}
  quartile={Q3},
  factor={3.0},
  doi={10.1007/s12021-021-09556-1}
}

@article{lekunberri2021identification,
  title={Identification and measurement of tropical tuna species in purse seiner catches using computer vision and deep learning},
  author={Lekunberri, Xabier and Ruiz, Jon and Quincoces, I{\~n}aki and Dornaika, Fadi and Arganda-Carreras, Ignacio and Fernandes, Jose A},
  journal={Ecological Informatics},
  pages={101495},
  year={2021},
  quartile={Q2},
  factor2020={3.43},
  publisher={Elsevier},
  doi={10.1016/j.ecoinf.2021.101495}
}


@article{laine2021avoiding,
  title={Avoiding a replication crisis in deep-learning-based bioimage analysis},
  author={Laine, Romain F and Arganda-Carreras, Ignacio and Henriques, Ricardo and Jacquemet, Guillaume},
  journal={Nature Methods},
  volume={18},
  number={10},
  pages={1136--1144},
  year={2021},
  publisher={Nature Publishing Group},
  quartile={Q1},
  factor2020={28.55},
  doi={10.1038/s41592-021-01284-3}  
}

@article{hammoudi2021deep,
  title={Deep learning on chest x-ray images to detect and evaluate pneumonia cases at the era of covid-19},
  author={Hammoudi, Karim and Benhabiles, Halim and Melkemi, Mahmoud and Dornaika, Fadi and Arganda-Carreras, Ignacio and Collard, Dominique and Scherpereel, Arnaud},
  journal={Journal of Medical Systems},
  volume={45},
  number={7},
  pages={1--10},
  year={2021},
  publisher={Springer},
  quartile={Q1},
  factor={4.920},
  doi={10.1007/s10916-021-01745-4}
}

@incollection{nunez2021exploiting,
  title={Exploiting Egocentric Cues for Action Recognition for Ambient Assisted Living Applications},
  author={N{\'u}{\~n}ez-Marcos, Adri{\'a}n and Azkune, Gorka and Arganda-Carreras, Ignacio},
  booktitle={Emerging Technologies in Biomedical Engineering and Sustainable TeleMedicine},
  pages={131--158},
  year={2021},
  publisher={Springer}
}

@article{elu2021inferring,
  title={Inferring spatial relations from textual descriptions of images},
  author={Elu, Aitzol and Azkune, Gorka and de Lacalle, Oier Lopez and Arganda-Carreras, Ignacio and Soroa, Aitor and Agirre, Eneko},
  journal={Pattern Recognition},
  volume={113},
  pages={107847},
  year={2021},
  publisher={Elsevier},
  quartile={Q1},
  factor={8.518},
  doi={10.1016/j.patcog.2021.107847}
}

@article{moujahid2021efficient,
  title={Efficient and compact face descriptor for driver drowsiness detection},
  author={Moujahid, Abdelmalik and Dornaika, Fadi and Arganda-Carreras, Ignacio and Reta, Jorge},
  journal={Expert Systems with Applications},
  volume={168},
  pages={114334},
  year={2021},
  publisher={Elsevier},
  quartile={Q1},
  factor={8.665},
  doi={0.1016/j.eswa.2020.114334}
}

@article{perez2020freeze,
  title={Freeze-frame imaging of synaptic activity using SynTagMA},
  author={Perez-Alvarez, Alberto and Fearey, Brenna C and O’Toole, Ryan J and Yang, Wei and Arganda-Carreras, Ignacio and Lamothe-Molina, Paul J and Moeyaert, Benjamien and Mohr, Manuel A and Panzera, Lauren C and Schulze, Christian and Schreiter, Eric R and Wiegert, J Simon and Gee, Christine E and Hoppa, Michael B and Oertner, Thomas G},
  journal={Nature communications},
  volume={11},
  number={1},
  pages={1--16},
  year={2020},
  quartile={Q1},
  factor={14.919},
  publisher={Nature Publishing Group},
  doi={10.1038/s41467-020-16315-4}
}

@article{borovec2020anhir,
  title={ANHIR: automatic non-rigid histological image registration challenge},
  author={Borovec, Jiří and Kybic, Jan and Arganda-Carreras, Ignacio and Sorokin, Dmitry V. and Bueno, Gloria and Khvostikov, Alexander V. and Bakas, Spyridon and Chang, Eric I-Chao and Heldmann, Stefan and Kartasalo, Kimmo and Latonen, Leena and Lotz, Johannes and Noga, Michelle and Pati, Sarthak and Punithakumar, Kumaradevan and Ruusuvuori, Pekka and Skalski, Andrzej and Tahmasebi, Nazanin and Valkonen, Masi and Venet, Ludovic and Wang, Yizhe and Weiss, Nick and Wodzinski, Marek and Xiang, Yu and Xu, Yan and Yan, Yan and Yushkevich, Paul and Zhao, Shengyu and Muñoz-Barrutia, Arrate},
  journal={IEEE transactions on medical imaging},
  volume={39},
  number={10},
  pages={3042--3052},
  year={2020},
  quartile={Q1},
  factor={10.048},
  publisher={IEEE},
  doi={10.1109/TMI.2020.2986331}
}

@article{gomez2019human,
  title={The human remains from Axlor (Dima, Biscay, northern Iberian Peninsula)},
  author={G{\'o}mez-Olivencia, Asier and L{\'o}pez-Onaindia, Diego and Sala, Nohemi and Balzeau, Antoine and Pantoja-P{\'e}rez, Ana and Arganda-Carreras, Ignacio and Arlegi, Mikel and Rios-Garaizar, Joseba and G{\'o}mez-Robles, Aida},
  journal={American Journal of Physical Anthropology},
  year={2019},
  publisher={Wiley Online Library}
  pages={1-17},
  doi={10.1002/ajpa.23989},
  quartile={Q1},
  issn={1096-8644},
  factor2018={2.662}
}

@article{dornaika2020robust,
  title={Robust regression with deep CNNs for facial age estimation: An empirical study},
  author={Dornaika, F and Bekhouche, SE and Arganda-Carreras, I},
  journal={Expert Systems with Applications},
  volume={141},
  pages={112942},
  year={2020},
  publisher={Elsevier},
  doi={10.1016/j.eswa.2019.112942},
  quartile={Q1},
  issn={0957-4174},
  factor={6.954}
}

@article{dornaika2020toward,
  title={Toward graph-based semi-supervised face beauty prediction},
  author={Dornaika, Fadi and Wang, Kunwei and Arganda-Carreras, Ignacio and Elorza, Anne and Moujahid, Abdelmalik},
  journal={Expert Systems with Applications},
  volume={142},
  pages={112990},
  year={2020},
  publisher={Elsevier},
  doi={10.1016/j.eswa.2019.112990},
  quartile={Q1},
  issn={0957-4174},
  factor={6.954}
}

@article{dornaika2020image,
  title={Image-based face beauty analysis via graph-based semi-supervised learning},
  author={Dornaika, Fadi and Elorza, A and Wang, K and Arganda-Carreras, Ignacio},
  journal={Multimedia Tools and Applications},
  volume={79},
  number={3},
  pages={3005--3030},
  year={2020},
  publisher={Springer},
  doi={10.1007/s11042-019-08206-8},
  quartile={Q3},
  factor={2.757},
  issn={1573-7721}
}




@article{dornaika2019transfer,
  title={Transfer learning and feature fusion for kinship verification},
  author={Dornaika, F and Arganda-Carreras, I and Serradilla, O},
  journal={Neural Computing and Applications},
  pages={1--13},
  year={2019},
  publisher={Springer},
  doi={10.1007/s00521-019-04201-0},
  quartile={Q1},
  issn={0941-0643},
  factor2018={4.664}
}

@article{dornaika2019nonlinear,
  title={Nonlinear, flexible, semisupervised learning scheme for face beauty scoring},
  author={Dornaika, Fadi and Elorza, Anne and Wang, Kunwei and Arganda-Carreras, Ignacio},
  journal={Journal of Electronic Imaging},
  volume={28},
  number={4},
  pages={043013},
  year={2019},
  publisher={International Society for Optics and Photonics},
  factor={0.924},
  issn={1017-9909},
  quartile={Q4},
  doi={10.1117/1.JEI.28.4.043013}
}

@article{abdeladim2019multicolor,
  title={Multicolor multiscale brain imaging with chromatic multiphoton serial microscopy},
  author={Abdeladim, Lamiae and Matho, Katherine S and Clavreul, Sol{\`e}ne and Mahou, Pierre and Sintes, Jean-Marc and Solinas, Xavier and Arganda-Carreras, Ignacio and Turney, Stephen G and Lichtman, Jeff W and Chessel, Anatole and Bemelmans, Alexis-Pierre and Loulier, Karine and Supatto, Willy and Livet, Jean and Beaurepaire, Emmanuel},
  journal={Nature communications},
  volume={10},
  number={1},
  pages={1662},
  year={2019},
  publisher={Nature Publishing Group},
  factor={11.878},
  issn={2041-1723},
  quartile={Q1},
  doi={10.1038/s41467-019-09552-9}
}

@article{gordon2019division,
  title={Division of labor and brain evolution in insect societies: Neurobiology of extreme specialization in the turtle ant Cephalotes varians},
  author={Gordon, Darcy Greer and Zelaya, Alejandra and Arganda-Carreras, Ignacio and Arganda, Sara and Traniello, James FA},
  journal={PLoS One},
  volume={14},
  number={3},
  pages={e0213618},
  year={2019},
  publisher={Public Library of Science},
  factor={2.776},
  issn={1932-6203},
  doi={10.1371/journal.pone.0213618},
  quartile={Q1}
}

@article{dornaika2019age,
  title={Age estimation in facial images through transfer learning},
  author={Dornaika, Fadi and Arganda-Carreras, Ignacio and Belver, Carlos},
  journal={Machine Vision and Applications},
  volume={30},
  number={1},
  pages={177--187},
  year={2019},
  publisher={Springer},
  factor={1.788},
  issn={0932-8092},
  quartile={Q2}
}

@article{olazabal2019wdr20,
  title={WDR20 regulates shuttling of the USP12 deubiquitinase complex between the plasma membrane, cytoplasm and nucleus},
  author={Olazabal-Herrero, Anne and Sendino, Maria and Arganda-Carreras, Ignacio and Rodr{\'\i}guez, Jose Antonio},
  journal={European journal of cell biology},
  volume={98},
  number={1},
  pages={12--26},
  year={2019},
  publisher={Elsevier},
  factor={3.024},
  issn={0171-9335},
  quartile={Q3},
  doi={10.1016/j.ejcb.2018.10.003}
}

@article{malhan2018optimized,
  title={An optimized plugin to perform automated histomorphometry of bone parameters},
  author={Malhan, Deeksha and Muelke, Matthias and Rosch, Sebastian and Schaefer, Annemarie Barbara and Merboth, Felix and Weisweiler, David and Heiss, Christian and Arganda-Carreras, Ignacio and El Khassawna, Thaqif},
  journal={Frontiers in Endocrinology},
  volume={9},
  pages={666},
  year={2018},
  publisher={Frontiers},
  factor={3.634},
  issn={1664-2392},
  quartile={Q2},
  doi={10.3389/fendo.2018.00666}
  
}

@InProceedings{dornaika2018image,
  title={Image-Based Driver Drowsiness Detection},
  author={Dornaika, F and Khattar, F and Reta, J and Arganda-Carreras, I and Hernandez, M and Ruichek, Y},
  booktitle={Video Analytics. Face and Facial Expression Recognition},
  pages={61--71},
  year={2019},
  publisher={Springer, Cham},
  isbn={978-3-030-12177-8},
  doi={10.1007/978-3-030-12177-8_6}
}



@InProceedings{aranjuelo2018,
author="Aranjuelo, Nerea
and Unzueta, Luis
and Arganda-Carreras, Ignacio
and Otaegui, Oihana",
editor="Perales, Francisco Jos{\'e}
and Kittler, Josef",
title="Multimodal Deep Learning for Advanced Driving Systems",
booktitle="Articulated Motion and Deformable Objects",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="95--105",
abstract="Multimodal deep learning is about learning features over multiple modalities. Impressive progress has been made in deep learning solutions that rely on a single sensor modality for advanced driving. However, these approaches are limited to cover certain functionalities. The potential of multimodal sensor fusion has been very little exploited, although research vehicles are commonly provided with various sensor types. How to combine their data to achieve a complex scene analysis and improve therefore robustness in driving is still an open question. While different surveys have been done for intelligent vehicles or deep learning, to date no survey on multimodal deep learning for advanced driving exists. This paper attempts to narrow this gap by providing the first review that analyzes existing literature and two indispensable elements: sensors and datasets. We also provide our insights on future challenges and work to be done.",
isbn="978-3-319-94544-6"
}


@article{arganda2018statistically,
  title={A Statistically Representative Atlas for Mapping Neuronal Circuits in the Drosophila Adult Brain},
  author={Arganda-Carreras, Ignacio and Manoliu, Tudor and Mazuras, Nicolas and Schulze, Florian and Iglesias, Juan E and B{\"u}hler, Katja and Jenett, Arnim and Rouyer, Fran{\c{c}}ois and Andrey, Philippe},
  journal={Frontiers in neuroinformatics},
  volume={12},
  pages={13},
  year={2018},
  publisher={Frontiers},
  factor={2.680},
  issn={1662-5196},
  quartile={Q1},
  doi={10.3389/fninf.2018.00013}
}

@article{nunez2017vision,
  title={Vision-Based Fall Detection with Convolutional Neural Networks},
  author={N{\'u}{\~n}ez-Marcos, Adri{\'a}n and Azkune, Gorka and Arganda-Carreras, Ignacio},
  journal={Wireless Communications and Mobile Computing},
  volume={2017},
  year={2017},
  pages={16},
  publisher={Hindawi},
  factor={0.869},
  issn={1530-8669},
  quartile={Q4},
  doi={10.1155/2017/9474806}
}

@article{arganda2017trainable,
  title={{Trainable Weka Segmentation}: a machine learning tool for microscopy pixel classification},
  author={Arganda-Carreras, Ignacio and Kaynig, Verena and Rueden, Curtis and Eliceiri, Kevin W and Schindelin, Johannes and Cardona, Albert and Sebastian Seung, H},
  journal={Bioinformatics},
  volume={33},
  number={15},
  pages={2424--2426},
  year={2017},
  publisher={Oxford University Press},
  factor={5.481},
  issn={1367-4803},
  quartile={Q1},
  doi={10.1093/bioinformatics/btx180}
}

@article{belver2017evaluating,
  title={Evaluating Age Estimation Using Deep Convolutional Neural Nets},
  author={Belver, C and Arganda-Carreras, I and Dornaika, F},
  journal={Electronic Imaging},
  volume={2017},
  number={17},
  pages={100--105},
  year={2017},
  publisher={Society for Imaging Science and Technology},
  factor={0.780},
  issn={1017-9909},
  quartile={Q4},
  doi={10.2352/ISSN.2470-1173.2017.17.COIMG-432}
}

@book{arganda2017designing,
  title={Designing Image Analysis Pipelines in Light Microscopy: A Rational Approach},
  author={Arganda-Carreras, Ignacio and Andrey, Philippe},
  journal={Light Microscopy: Methods and Protocols},
  pages={185--207},
  year={2017},
  publisher={Springer},
  doi={10.1007/978-1-4939-6810-7_13},
  isbn={978-1-4939-6808-4}
}

@incollection{belver2016comparative,
  title={Comparative Study of Human Age Estimation Based on Hand-Crafted and Deep Face Features},
  author={Belver, C and Arganda-Carreras, I and Dornaika, Fadi},
  booktitle={Video Analytics. Face and Facial Expression Recognition and Audience Measurement},
  pages={98--112},
  year={2016},
  publisher={Springer},
  isbn={978-1-4939-6808-4}
}

@article{dornaika2016empirical,
  title={An Empirical Study of Global Descriptors for Image-based Localization in Dense Urban Scenes},
  author={Dornaika, Fadi and Assoum, Ammar and Moujahid, Abdelmalik and Arganda-Carreras, Ignacio},
  journal={International Journal of Sensors Wireless Communications and Control},
  volume={6},
  number={3},
  pages={142--152},
  year={2016},
  publisher={Bentham Science Publishers},
  issn={2210-3287},
  doi={10.2174/2210327906666160606162929}
}

@article{Legland2016,
  title={{MorphoLibJ}: integrated library and plugins for mathematical morphology with {ImageJ}},
  author={Legland, David and Arganda-Carreras, Ignacio and Andrey, Philippe},
  journal={Bioinformatics},
  volume={32},
  number={22},
  pages={3532--3534},
  year={2016},
  publisher={Oxford Univ Press},
  doi = {10.1093/bioinformatics/btw413}, 
  abstract={Motivation: Mathematical morphology provides many powerful operators for processing 2D and 3D images. However, most mathematical morphology plugins currently implemented for the popular ImageJ/Fiji platform are limited to the processing of 2D images.
Results: The MorphoLibJ library proposes a large collection of generic tools based on mathematical morphology to process binary and grey-level 2D and 3D images, integrated into user-friendly plugins. We illustrate how MorphoLibJ can facilitate the exploitation of 3D images of plant tissues.
Availability: MorphoLibJ is freely available at http://ijpb.github.io/MorphoLibJ/

Contact: david.legland@nantes.inra.fr

Supplementary information: Supplementary data are available at Bioinformatics online.}, 
  URL = {http://bioinformatics.oxfordjournals.org/content/early/2016/07/12/bioinformatics.btw413.abstract}, 
  eprint = {http://bioinformatics.oxfordjournals.org/content/early/2016/07/12/bioinformatics.btw413.full.pdf+html},
  factor={7.307},
  issn={1367-4803},
  quartile={Q1}
}

@ARTICLE{Arganda-Carreras2015challenge,
  AUTHOR={Arganda-Carreras, Ignacio  and  Turaga, Srinivas C  and  Berger, Daniel R  and  Ciresan, Dan  and  Giusti, Alessandro  and  Gambardella, Luca Maria  and  Schmidhuber, Jürgen  and  Laptev, Dmitry  and  Dwivedi, Sarvesh  and  Buhmann, Joachim M  and  Liu, Ting  and  Seyedhosseini, Mojtaba  and  Tasdizen, Tolga  and  Kamentsky, Lee  and  Burget, Radim  and  Uher, Vaclav  and  Tan, Xiao  and  Sun, Cangming  and  Pham, Tuan  and  Bas, Erhan  and  Uzunbas, Mustafa Gokhan  and  Cardona, Albert  and  Schindelin, Johannes  and  Seung, H. Sebastian},   
  TITLE={Crowdsourcing the creation of image segmentation algorithms for connectomics},      
  JOURNAL={Frontiers in Neuroanatomy},      
  VOLUME={9},      
  YEAR={2015},      
  NUMBER={142},     
  URL={http://www.frontiersin.org/neuroanatomy/10.3389/fnana.2015.00142/abstract},       
  DOI={10.3389/fnana.2015.00142},      
  ISSN={1662-5129} ,      
  ABSTRACT={To stimulate progress in automating the reconstruction of neural circuits, we organized the first international challenge on 2D segmentation of electron microscopic (EM) images of the brain. Participants submitted boundary maps predicted for a test set of images, and were scored based on their agreement with a consensus of human expert annotations. The winning team had no prior experience with EM images, and employed a convolutional network. This “deep learning” approach has since become accepted as a standard for segmentation of EM images. The challenge has continued to accept submissions, and the best so far has resulted from cooperation between two teams. The challenge has probably saturated, as algorithms cannot progress beyond limits set by ambiguities inherent in 2D scoring and the size of the test dataset. Retrospective evaluation of the challenge scoring system reveals that it was not sufficiently robust to variations in the widths of neurite borders. We propose a solution to this problem, which should be useful for a future 3D segmentation challenge.},
  factor={3.260},
  quartile={Q1}
}

@article{cabrera2015phenotyping,
	author = {Cabrera, Javier and Díaz-Manzano, Fernando E. and Barcala, Marta and Arganda-Carreras, Ignacio and de Almeida-Engler, Janice and Engler, Gilbert and Fenoll, Carmen and Escobar, Carolina},
	title = {Phenotyping nematode feeding sites: three-dimensional reconstruction and volumetric measurements of giant cells induced by root-knot nematodes in Arabidopsis},
	journal = {New Phytologist},
	volume = {206},
	number = {2},
	issn = {1469-8137},
	url = {http://dx.doi.org/10.1111/nph.13249},
	doi = {10.1111/nph.13249},
	pages = {868--880},
	keywords = {Arabidopsis, giant cells (GCs), phenotyping, root-knot nematodes (RKN), three-dimensional reconstruction},
	year = {2015},
	note = {2014-18060},
	factor = {7.210},
	quartile = {Q1}
}

@article{kim2015mapping,
  title={Mapping Social Behavior-Induced Brain Activation at Cellular Resolution in the Mouse},
  author={Kim, Yongsoo and Venkataraju, Kannan Umadevi and Pradhan, Kith and Mende, Carolin and Taranda, Julian and Turaga, Srinivas C and Arganda-Carreras, Ignacio and Ng, Lydia and Hawrylycz, Michael J and Rockland, Kathleen S and Seung, H Sebastian and Osten, Pavel},
  journal={Cell reports},
  volume={10},
  number={2},
  pages={292--305},
  year={2015},
  publisher={Cell Press},
  issn={2211-1247},
  quartile={Q1},
  doi={10.1016/j.celrep.2014.12.014}
}

@article{poulet2015nucleusj,
  title={Nucleus{J}: an {ImageJ} plugin for quantifying {3D} images of interphase nuclei},
  author={Poulet, Axel and Arganda-Carreras, Ignacio and Legland, David and Probst, Aline V and Andrey, Philippe and Tatout, Christophe},
  journal={Bioinformatics},
  volume={31},
  number={7},
  pages={1144--1146},
  year={2015},
  publisher={Oxford Univ Press},
  quartile={Q1},
  doi={10.1093/bioinformatics/btu774},
  issn={1367-4803}
}

@article{Miyasaka2014,
	title={{Olfactory projectome in the zebrafish forebrain revealed by genetic single-neuron labelling}},
	author={Nobuhiko Miyasaka and Ignacio Arganda-Carreras and Noriko Wakisaka and Miwa Masuda and Uygar S\"{u}mb\"{u}l and H. Sebastian Seung and Yoshihiro Yoshihara},
	journal={Nature Communications},
	volume={5},
    year={2014},
    publisher={Nature Publishing Group}
    factor={11.470},
    issn={2041-1723},
    quartile={Q1},
    doi={10.1038/ncomms4639},
	factor2014={11.470}
}


@article{gul2014generic,
  title={A generic classification-based method for segmentation of nuclei in {3D} images of early embryos},
  author={Gul-Mohammed, Jaza and Arganda-Carreras, Ignacio and Andrey, Philippe and Galy, Vincent and Boudier, Thomas},
  journal={BMC bioinformatics},
  volume={15},
  number={1},
  pages={9},
  year={2014},
  publisher={BioMed Central Ltd},
  issn={1471-2105},
  quartile={Q1},
  doi={10.1186/1471-2105-15-9}
}


ARTICLE{Arganda-Carreras2013tws,
  author = {Ignacio Arganda-Carreras and Verena Kaynig and Johannes Schindelin
	and Albert Cardona and H. Sebastian Seung},
  title = {Trainable Weka Segmentation: a framework for machine learning based
	segmentation},
  year = {2013},
  note = {In preparation},
  owner = {iarganda},
  timestamp = {2012.03.15}
}


@ARTICLE{Ragan2012,
  author = {Timothy Ragan and Lolahon R. Kadiri and Kannan Umadevi Venkataraju
	and Karsten Bahlmann and Julian Taranda and Ignacio Arganda-Carreras
	and Jason Sutin and H. Sebastian Seung and Pavel Osten},
  title = {Serial two-photon tomography: an automated method for ex-vivo mouse
	brain imaging},
  journal = {Nature Methods},
  year = {2012},
  volume = {9},
  pages = {252-258},
  number = {3},
  month = {January},
  owner = {iarganda},
  timestamp = {2011.12.02},
  url = {http://dx.doi.org/10.1038/nmeth.1854},
  quartile={Q1}
}

@ARTICLE{Schindelin2012,
  author = {Johannes Schindelin and Ignacio Arganda-Carreras and Erwin Frise
	and Verena Kaynig and Mark Longair and Tobias Pietzsch and Stephan
	Preibisch and Curtis Rueden and Stephan Saalfeld and Benjamin Schmid
	and Jean-Yves Tinevez and Daniel James White and Volker Hartenstein
	and Kevin Eliceiri and Pavel Tomancak and Albert Cardona},
  title = {Fiji: an open-source platform for biological-image analysis},
  journal = {Nature Methods},
  year = {2012},
  volume = {9},
  pages = {676--682},
  month = {June},
  abstract = {Fiji is a distribution of the popular open-source software ImageJ
	focused on biological-image analysis. Fiji uses modern software engineering
	practices to combine powerful software libraries with a broad range
	of scripting languages to enable rapid prototyping of image-processing
	algorithms. Fiji facilitates the transformation of new algorithms
	into ImageJ plugins that can be shared with end users through an
	integrated update system. We propose Fiji as a platform for productive
	collaboration between computer science and biology research communities.},
  doi = {10.1038/nmeth.2019},
  owner = {iarganda},
  timestamp = {2012.06.29},
  quartile={Q1},
  issn={1548-7091},
  factor2012={23.565}
}

@ARTICLE{Cardona2012,
  author = {Cardona, , Albert AND Saalfeld, , Stephan AND Schindelin, , Johannes
	AND Arganda-Carreras, , Ignacio AND Preibisch, , Stephan AND Longair,
	, Mark AND Tomancak, , Pavel AND Hartenstein, , Volker AND Douglas,
	, Rodney J.},
  title = {{TrakEM2} Software for Neural Circuit Reconstruction},
  journal = {PLoS ONE},
  year = {2012},
  volume = {7},
  pages = {e38011},
  number = {6},
  month = {06},
  abstract = {<p>A key challenge in neuroscience is the expeditious reconstruction
	of neuronal circuits. For model systems such as <italic>Drosophila</italic>
	and <italic>C. elegans</italic>, the limiting step is no longer the
	acquisition of imagery but the extraction of the circuit from images.
	For this purpose, we designed a software application, TrakEM2, that
	addresses the systematic reconstruction of neuronal circuits from
	large electron microscopical and optical image volumes. We address
	the challenges of image volume composition from individual, deformed
	images; of the reconstruction of neuronal arbors and annotation of
	synapses with fast manual and semi-automatic methods; and the management
	of large collections of both images and annotations. The output is
	a neural circuit of 3d arbors and synapses, encoded in NeuroML and
	other formats, ready for analysis.</p>},
  doi = {10.1371/journal.pone.0038011},
  owner = {iarganda},
  publisher = {Public Library of Science},
  timestamp = {2012.07.06},
  url = {http://dx.doi.org/10.1371%2Fjournal.pone.0038011},
  quartile={Q1}
}

@ARTICLE{Doube2010,
  author = {Doube, Michael and Klosowski, Michal M. and Arganda-Carreras, Ignacio
	and Cordelieres, Fabrice P. and Dougherty, Robert P. and Jackson,
	Jonathan S. and Schmid, Benjamin and Hutchinson, John R. and Shefelbine,
	Sandra J.},
  title = {{BoneJ}: Free and extensible bone image analysis in {ImageJ}},
  journal = {BONE},
  year = {2010},
  volume = {{47}},
  pages = {{1076-1079}},
  number = {{6}},
  month = {December},
  abstract = {Bone geometry is commonly measured on computed tomographic (CT) and
	X-ray microtomographic ([mu]CT) images. We obtained hundreds of CT,
	[mu]CT and synchrotron [mu]CT images of bones from diverse species
	that needed to be analysed remote from scanning hardware, but found
	that available software solutions were expensive, inflexible or methodologically
	opaque. We implemented standard bone measurements in a novel ImageJ
	plugin, BoneJ, with which we analysed trabecular bone, whole bones
	and osteocyte lacunae. BoneJ is open source and free for anyone to
	download, use, modify and distribute.},
  address = {{360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA}},
  affiliation = {{Doube, M (Reprint Author), Univ London Imperial Coll Sci Technol
	\& Med, Dept Bioengn, London SW7 2AZ, England. Doube, M; Klosowski,
	MM; Shefelbine, SJ, Univ London Imperial Coll Sci Technol \& Med,
	Dept Bioengn, London SW7 2AZ, England. Arganda-Carreras, I, MIT,
	Dept Brain \& Cognit Sci, Cambridge, MA 02139 USA. Cordelieres, FP,
	CNRS, Inst Curie, Sect Rech Plate Forme Imagerie Cellulaire \& Tissu,
	UMR 3348, F-91405 Orsay, France. Dougherty, RP, OptiNav Inc, Redmond,
	WA USA. Jackson, JS, Harvard Univ, Brigham \& Womens Hosp, Sch Med,
	Dept Neurol, Boston, MA 02115 USA. Schmid, B, Univ Wurzburg, Dept
	Neurobiol \& Genet, D-97070 Wurzburg, Germany. Hutchinson, JR, Royal
	Vet Coll, Struct \& Mot Lab, Hatfield AL9 7TA, Herts, England.}},
  doi = {{10.1016/j.bone.2010.08.023}},
  issn = {{8756-3282}},
  keywords = {Bone; Tomography; Image; Open source; Software; Morphometry},
  language = {{English}},
  publisher = {{ELSEVIER SCIENCE INC}},
  type = {{Article}},
  quartile={Q1},
  factor2010={4.601}
}

@ARTICLE{Arganda-Carreras2010,
  author = {Arganda-Carreras, Ignacio and Fernandez-Gonzalez, Rodrigo and Mu\~{n}oz-Barrutia,
	Arrate and {Ortiz-de-Solorzano}, Carlos},
  title = {{{3D} Reconstruction of Histological Sections: Application to Mammary
	Gland Tissue}},
  journal = {Microscopy Research and Technique},
  year = {2010},
  volume = {{73}},
  pages = {{1019-1029}},
  number = {{11}},
  month = {{October}},
  abstract = {{In this article, we present a novel method for the automatic 3D reconstruction
	of thick tissue blocks from 2D histological sections. The algorithm
	completes a high-content (multi-scale, multifeature) imaging system
	for simultaneous morphological and molecular analysis of thick tissue
	samples. This computer-based system integrates image acquisition,
	annotation, registration, and three-dimensional reconstruction. We
	present an experimental validation of this tool using both synthetic
	and real data. In particular, we present the 3D reconstruction of
	an entire mouse mammary gland and demonstrate the integration of
	high-resolution molecular data. Microsc. Res. Tech. 73: 1019-1029,
	2010. (C) 2010 Wiley-Liss, Inc.}},
  owner = {iarganda},
  timestamp = {2010.02.24},
  quartile={Q2},
  factor2010={1.721},
  doi={10.1002/jemt.20829},
  issn={8756-3282}
 }


@ARTICLE{Arganda-Carreras2010b,
  author = {Arganda-Carreras, Ignacio and Sorzano, Carlos ~{O}.~{S}. and Th\'{e}venaz, Philippe and Mu\~{n}{oz-Barrutia},
	Arrate and Kybic, Jan and Marabini, Roberto and Carazo, Jose Maria and {Ortiz-de-Solorzano}, Carlos},
  title = {Non-rigid consistent registration of {2D} image sequences},
  journal = {Physics in Medicine and Biology},
  year = {2010},
  volume = {55},
  pages = {6215},
  number = {20},
  abstract = {We present a novel algorithm for the registration of 2D image sequences
	that combines the principles of multiresolution B-spline-based elastic
	registration and those of bidirectional consistent registration.
	In our method, consecutive triples of images are iteratively registered
	to gradually extend the information through the set of images of
	the entire sequence. The intermediate results are reused for the
	registration of the following triple. We choose to interpolate the
	images and model the deformation fields using B-spline multiresolution
	pyramids. Novel boundary conditions are introduced to better characterize
	the deformations at the boundaries. In the experimental section,
	we quantitatively show that our method recovers from barrel/pincushion
	and fish-eye deformations with subpixel error. Moreover, it is more
	robust against outliers—occasional strong noise and large rotations—than
	the state-of-the-art methods. Finally, we show that our method can
	be used to realign series of histological serial sections, which
	are often heavily distorted due to folding and tearing of the tissues.},
  owner = {iarganda},
  timestamp = {2010.10.01},
  url = {http://stacks.iop.org/0031-9155/55/i=20/a=012},
  quartile={Q1},
  factor2010={3.057},
  doi={10.1088/0031-9155/55/20/012},
  issn={1361-6560}
}

@ARTICLE{cardona2010,
  author = {Cardona, Albert and Saalfeld, Stephan and Arganda-Carreras, Ignacio
	and Pereanu, Wayne and Schindelin, Johannes and Hartenstein, Volker},
  title = {{Identifying Neuronal Lineages of Drosophila by Sequence Analysis
	of Axon Tracts}},
  journal = {{Journal of Neuroscience}},
  year = {2010},
  volume = {{30}},
  pages = {{7538-7553}},
  number = {{22}},
  month = {{June 2}},
  abstract = {{The Drosophila brain is formed by an invariant set of lineages, each
	of which is derived from a unique neural stem cell (neuroblast) and
	forms a genetic and structural unit of the brain. The task of reconstructing
	brain circuitry at the level of individual neurons can be made significantly
	easier by assigning neurons to their respective lineages. In this
	article we address the automation of neuron and lineage identification.
	We focused on the Drosophila brain lineages at the larval stage when
	they form easily recognizable secondary axon tracts (SATs) that were
	previously partially characterized. We now generated an annotated
	digital database containing all lineage tracts reconstructed from
	five registered wild-type brains, at higher resolution and including
	some that were previously not characterized. We developed a method
	for SAT structural comparisons based on a dynamic programming approach
	akin to nucleotide sequence alignment and a machine learning classifier
	trained on the annotated database of reference SATs. We quantified
	the stereotypy of SATs by measuring the residual variability of aligned
	wild-type SATs. Next, we used our method for the identification of
	SATs within wild-type larval brains, and found it highly accurate
	(93-99\%). The method proved highly robust for the identification
	of lineages in mutant brains and in brains that differed in developmental
	time or labeling. We describe for the first time an algorithm that
	quantifies neuronal projection stereotypy in the Drosophila brain
	and use the algorithm for automatic neuron and lineage recognition.}},
  address = {{11 DUPONT CIRCLE, NW, STE 500, WASHINGTON, DC 20036 USA}},
  affiliation = {{Cardona, A (Reprint Author), Univ Zurich, Inst Neuroinformat, Winterthurerstr
	190, CH-8057 Zurich, Switzerland. {[}Cardona, Albert; Arganda, Ignacio]
	Univ Zurich, Inst Neuroinformat, CH-8057 Zurich, Switzerland. {[}Cardona,
	Albert; Arganda, Ignacio] Swiss Fed Inst Technol, CH-8057 Zurich,
	Switzerland. {[}Saalfeld, Stephan; Schindelin, Johannes] Max Planck
	Inst Mol Cell Biol \& Genet, D-01307 Dresden, Germany. {[}Pereanu,
	Wayne] Howard Hughes Med Inst Janelia Farm, Ashburn, VA 20147 USA.
	{[}Hartenstein, Volker] Univ Calif Los Angeles, Dept Mol Cell \&
	Dev Biol, Los Angeles, CA 90095 USA.}},
  author-email = {{acardona@ini.phys.ethz.ch}},
  doc-delivery-number = {{604OK}},
  doi = {{10.1523/JNEUROSCI.0186-10.2010}},
  funding-acknowledgement = {{European Union {[}216593]; National Institutes of Health {[}R01 NS29357-15]}},
  funding-text = {{This work was funded by European Union Grant 216593 ``Self Constructing{''}
	(SECO) and National Institutes of Health Grant R01 NS29357-15 (to
	V.H.). We thank Shana Spindler and Louie Garcia for confocal image
	stacks of glia-less brains and dopaminergic neurons and Sergio Jimenez
	for help with designing and setting up a classifier with WEKA. Thanks
	to Parvez Ahammad and Marta Zlatic for critical comments on this
	manuscript.}},
  issn = {{0270-6474}},
  journal-iso = {{J. Neurosci.}},
  keywords-plus = {{NERVOUS-SYSTEM LINEAGES; MUSHROOM BODY; BRAIN-DEVELOPMENT; PATTERN;
	NEUROPIL; RECONSTRUCTION; MELANOGASTER; TOOL; PRESPECIFICATION; NEUROECTODERM}},
  language = {{English}},
  number-of-cited-references = {{54}},
  publisher = {{SOC NEUROSCIENCE}},
  subject-category = {{Neurosciences}},
  times-cited = {{0}},
  type = {{Article}},
  unique-id = {{ISI:000278288200011}},
  quartile={Q1}
}

@ARTICLE{cossorzano2008,
  author = {Sorzano, Carlos ~{O}.~{S}. and Arganda-Carreras, Ignacio and Th{\'{e}}venaz,
	Philippe and Beloso, Ana and Morales, Gracia and Valdes, Israel and
	Perez-Garcia, Carmen and Castillo, Carmen and Garrido, Elisa and
	Unser, Michael},
  title = {Elastic Image Registration of 2{D} gels for differential and repeatability
	studies},
  journal = {Proteomics},
  year = {2008},
  volume = {8},
  pages = {62-65},
  quartile={Q1},
  doi={10.1002/pmic.200700473},
  issn={1615-9861}
}

@INPROCEEDINGS{arganda-carreras2006,
  author = {Arganda-Carreras, Ignacio and Sorzano, Carlos ~{O}.~{S}. and Marabini,
	Roberto and Carazo, Jose-Maria and {Ortiz-de-Solorzano}, Carlos and
	Kybic, Jan},
  title = {Consistent and Elastic Registration of Histological Sections Using
	Vector-Spline Regularization},
  booktitle = {Computer Vision Approaches to Medical Image Analysis},
  year = {2006},
  volume = {4241},
  series = {Lecture Notes in Computer Science},
  pages = {85-95},
  month = {May},
  publisher = {Springer Berlin/Heidelberg},
  city = {Graz, Austria}
}

