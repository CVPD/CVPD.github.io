@article{bi2024sample,
title = {Sample-weighted fused graph-based semi-supervised learning on multi-view data},
journal = {Information Fusion},
volume = {104},
pages = {102175},
year = {2024},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2023.102175},
url = {https://www.sciencedirect.com/science/article/pii/S1566253523004918},
author = {Jingjun Bi and Fadi Dornaika},
keywords = {Multi-view data, Semi-supervised classification, Semi-supervised graph construction, Fused graph, Graph convolutional networks},
abstract = {Research in semi-supervised learning on graphs has attracted more and more attention in recent years, as learning on graphs is applied in more and more domains and labeling data is expensive and time-consuming. Some scenarios have inherent graph structures in their data, such as the relationships between people in social scenarios or the relationships between objects that are mutually referenced. However, there are also many data types without inherent graph structures, such as image data, and each image can be described with different features, which is a typical type of multi-view data. For image data and other non-graph data, there are significantly fewer deep learning approaches that target multi-view graph-based semi-supervised learning. This paper attempts to fill this gap. Based on the Graph Convolutional Network (GCN) architecture, we propose a Sample-weighted Fused Graph-based Semi-supervised Classification (WFGSC) method for multi-view data in this paper. It (i) constructs a semi-supervised graph in each view using a flexible model for joint graph and label estimation, (ii) obtains an additional graph based on the representation of nodes provided by the joint estimator, and then obtains a fused graph between all views, (iii) gives higher weights to hard-to-classify samples, (iv) proposes a loss function to train the GCN on the fused features and the consensus graph that integrates graph auto-encoder loss and label smoothing over the consensus graph. The results of our experiments on six multi-view datasets show that our WFGSC performs well on both fused graph construction and semi-supervised classification, and generally outperforms traditional GCNs and other multi-view semi-supervised multi-view classification methods.11Source code: https://github.com/BiJingjun/WFGSC.}
}

@article{dornaika2024overcoming,
  title={Overcoming graph topology imbalance for inductive and scalable semi-supervised learning},
  author={Dornaika, Fadi and Ibrahim, Zoulfikar and Bosaghzadeh, Alireza},
  journal={Applied Soft Computing},
  volume={151},
  pages={111164},
  year={2024},
  publisher={Elsevier},
  doi={10.1016/j.asoc.2023.111164},
  url={https://doi.org/10.1016/j.asoc.2023.111164},
  abstract={Graph-based semi-supervised learning (GSSL) has received much attention recently. Despite some progress made in this area by some recent methods, some limitations still need to be addressed. Namely, there are two main shortcomings. First, the graphs used are very often built in advance and independently of the task at hand, using a heuristic, and generally do not represent the true topology of the data. The second shortcoming is the ability of the model to handle a very large number of unlabeled samples. This can make the GSSL solution impractical from a computational resource perspective. In this paper, we propose the Weighted Simultaneous Graph Construction and Reduced Flexible Manifold Embedding (W-SGRFME) method, which is a scalable and inductive GSSL framework. The main contributions are as follows. First, we extend the concept of graph topology imbalance to large datasets. Second, we integrate the computed weights of the labeled samples into the unified semi-supervised model. The latter jointly estimates the labels of the unlabeled samples, the mapping of the feature space to the label space, and the graph matrix of the anchor graph. Moreover, the fusion of labels and features of anchors is used to adaptively construct the graph. Experimental results on three large datasets from semi-supervised learning show the effectiveness of the proposed scalable method. These datasets are NORB, RCV1, and Covtype. Experimental results on large datasets show the superiority of the proposed method over existing scalable models.}
}

@article{al2024clustering,
  title={Clustering using graph convolution networks},
  author={Al Jreidy, Maria and Constantin, Joseph and Dornaika, Fadi and Hamad, Denis},
  journal={Progress in Artificial Intelligence},
  pages={1--9},
  year={2024},
  publisher={Springer},
  doi={10.1007/s13748-023-00310-z},
  url={https://doi.org/10.1007/s13748-023-00310-z},
  abstract={Graph convolution networks (GCNs) have emerged as powerful approaches for semi-supervised classification of attributed graph data. In this paper, we introduce a novel objective function designed for training GCNs in an unsupervised learning setting, specifically for clustering purposes. Our proposed loss function is comprised solely of unsupervised components. The first component encompasses the kernel k-means objective function, which captures shared feature information among nodes, while the second component serves as a regularization term, promoting the smoothness of predicted clusters across the entire dataset. By employing this objective function, we preserve the strengths of conventional semi-supervised GCNs while adapting them to the demands of unsupervised clustering tasks. Experimental results, based on standard benchmark datasets, demonstrate that our unsupervised GCN outperforms contemporary state-of-the-art clustering algorithms.}
}

@ARTICLE{dornaika2024lgcoamix,
  author={Dornaika, Fadi and Sun, Danyang},
  journal={IEEE Transactions on Image Processing}, 
  title={LGCOAMix: Local and Global Context-and-Object-Part-Aware Superpixel-Based Data Augmentation for Deep Visual Recognition}, 
  year={2024},
  volume={33},
  number={},
  pages={205-215},
  abstract={Cutmix-based data augmentation, which uses a cut-and-paste strategy, has shown remarkable generalization capabilities in deep learning. However, existing methods primarily consider global semantics with image-level constraints, which excessively reduces attention to the discriminative local context of the class and leads to a performance improvement bottleneck. Moreover, existing methods for generating augmented samples usually involve cutting and pasting rectangular or square regions, resulting in a loss of object part information. To mitigate the problem of inconsistency between the augmented image and the generated mixed label, existing methods usually require double forward propagation or rely on an external pre-trained network for object centering, which is inefficient. To overcome the above limitations, we propose LGCOAMix, an efficient context-aware and object-part-aware superpixel-based grid blending method for data augmentation. To the best of our knowledge, this is the first time that a label mixing strategy using a superpixel attention approach has been proposed for cutmix-based data augmentation. It is the first instance of learning local features from discriminative superpixel-wise regions and cross-image superpixel contrasts. Extensive experiments on various benchmark datasets show that LGCOAMix outperforms state-of-the-art cutmix-based data augmentation methods on classification tasks, and weakly supervised object location on CUB200-2011. We have demonstrated the effectiveness of LGCOAMix not only for CNN networks, but also for Transformer networks. Source codes are available at https://github.com/DanielaPlusPlus/LGCOAMix.},
  keywords={Data augmentation, Training,Semantics, Visualization, Deep learning, Transformers, Kernel, Superpixel, data augmentation, context-and-object-part-aware, contrastive learning, local and global},
  doi={10.1109/TIP.2023.3336532},
  ISSN={1941-0042},
}

@article{sun2024data,
  title = {Data augmentation for deep visual recognition using superpixel based pairwise image fusion},
  journal = {Information Fusion},
  volume = {107},
  pages = {102308},
  year = {2024},
  issn = {1566-2535},
  doi = {https://doi.org/10.1016/j.inffus.2024.102308},
  url = {https://www.sciencedirect.com/science/article/pii/S1566253524000861},
  author = {Danyang Sun and Fadi Dornaika},
  keywords = {Superpixel, Image fusion, Data augmentation, Weighted contrastive learning loss, Local context},
  abstract = {Data augmentation is an important paradigm for boosting the generalization capability of deep learning in image classification tasks. Image augmentation using cut-and-paste strategies has shown very good performance improvement for deep learning. However, these existing methods often overlook the image's discriminative local context and rely on ad hoc regions consisting of square or rectangular local regions, leading to the loss of complete semantic object parts. In this work, we attempt to overcome these limitations and propose a superpixel-wise local-context-aware efficient image fusion approach for data augmentation. Our approach requires only one forward propagation using a superpixel attention-based label fusion with less computational complexity. The model is trained using a combination of a global classification of the fused (augmented) image loss, a superpixel-wise weighted local classification loss, and a superpixel-based weighted contrastive learning loss. The last two losses are based on the superpixel-aware attentive embeddings. Thus, the resulting deep encoder can learn both local and global features of the images while capturing object-part local context and information. Experiments on diverse benchmark image datasets indicate that the proposed method out-performs many region-based augmentation methods for visual recognition. We have demonstrated its effectiveness not only on CNN models but also on transformer models. The codes are accessible at https://github.com/DanielaPlusPlus/SAFuse.}
}

@INPROCEEDINGS{dornaika2023semi,
  author={Dornaika, Fadi and Baradaaji, Abdullah and Charafeddine, Jinan},
  booktitle={2023 International Conference on Computer and Applications (ICCA)}, 
  title={Semi-supervised Classification through Data and Label Graph Fusion}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={This study introduces a groundbreaking structure for semi-supervised learning based on graphs. Our technique provides an all-encompassing strategy that simultaneously tackles the challenges of label prediction and linear transformation. Specifically, the linear transformation we advocate is designed to forge a distinguishing subspace, thereby significantly compressing the data’s dimensionality.In advancing semi-supervised learning techniques, our framework particularly focuses on effectively utilizing the intrinsic data configuration and the provisional labels related to the unlabeled examples in our possession. This distinctive methodology leads to a more sophisticated and discriminative form of linear transformation. Tests carried out on authentic image datasets clearly validate the efficiency of the method we advocate. These tests repeatedly show enhanced performance in contrast to semi-supervised strategies that address the fusion of data and label deduction in isolation.},
  keywords={Estimation,Semisupervised learning,Iterative methods,Labeling,Graph-based semi-supervised learning,data graph,label graph,graph fusion,pattern recognition},
  doi={10.1109/ICCA59364.2023.10401729},
  ISSN={},
  month={Nov},
}
