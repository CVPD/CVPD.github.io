@article{sun2024lcamix,
  title = {LCAMix: Local-and-contour aware grid mixing based data augmentation for medical image segmentation},
  journal = {Information Fusion},
  volume = {110},
  pages = {102484},
  year = {2024},
  issn = {1566-2535},
  doi = {https://doi.org/10.1016/j.inffus.2024.102484},
  url = {https://www.sciencedirect.com/science/article/pii/S1566253524002628},
  author = {Danyang Sun and Fadi Dornaika and Jinan Charafeddine},
  keywords = {Data augmentation, Medical image segmentation, Superpixel, Focal and angular margin},
  abstract = {Medical image segmentation often faces challenges related to overfitting, primarily due to the limited and complex training samples. This challenge often prompts the use of self-supervised learning and data augmentation. However, self-supervised learning requires well-defined hand-crafted tasks and multiple training stages. On the other hand, basic image augmentation techniques like cropping, rotation, and flipping, effective for natural scene images, have limited efficacy for medical images due to their isotropic nature. While regional dropout regularization data augmentation methods have proven effective in image recognition tasks, their application in image segmentation is not as extensively studied. Additionally, existing augmentation methods often operate on square regions, leading to the loss of crucial contour information. This is particularly problematic for medical image segmentation tasks dealing with regions of interest characterized by intricate shapes. In this work, we introduce LCAMix, a novel data augmentation approach designed for medical image segmentation. LCAMix operates by blending two images and their segmentation masks based on their superpixels, incorporating a local-and-contour-aware strategy. The training process on augmented images adopts two auxiliary pretext tasks: firstly, classifying local superpixels in augmented images using an adaptive focal margin, leveraging segmentation ground truth masks as prior knowledge; secondly, reconstructing the two source images using mixed superpixels as mutual masks, emphasizing spatial sensitivity. Our method stands out as a simple, one-stage, model-agnostic, and plug-and-play data augmentation solution applicable to various segmentation tasks. Notably, it requires no external data or additional models. Extensive experiments validate its superior performance across diverse medical segmentation datasets and tasks. The source codes are available at https://github.com/DanielaPlusPlus/DataAug4Medical.}
}

@article{dornaika2023object,
  title = {Object-centric Contour-aware Data Augmentation Using Superpixels of Varying Granularity},
  journal = {Pattern Recognition},
  volume = {139},
  pages = {109481},
  year = {2023},
  issn = {0031-3203},
  doi = {https://doi.org/10.1016/j.patcog.2023.109481},
  url = {https://www.sciencedirect.com/science/article/pii/S0031320323001814},
  author = {Fadi Dornaika and Danyang Sun and Karim Hammoudi and Jinan Charafeddine and Adnane Cabani and Chongsheng Zhang},
  keywords = {Data augmentation, Cutmix, Object-centric Contour-aware, Discriminative regions, Attention, Superpixels},
  abstract = {Regional dropout strategies have demonstrated to be very effective in improving both the performance and the generalization capability of deep learning models. However, when such strategies are performed in a totally random manner, the background noise and label mismatch problems arise. To tackle such problems, existing approaches typically focus on regions with the highest distinctiveness. Yet, there are two main drawbacks of existing approaches: (I) Many existing region-based augmentation methods can only use rectangular regions, resulting in the loss of object contour information; (II) Deterministic selection of the most discriminative regions leads to poor diversification in data augmentation. In fact, a trade-off is needed between diversification and concentration, which can decrease the undesirable noise. In this paper, we propose a novel object-centric contour-aware CutMix data augmentation strategy with arbitrary- shape and size superpixel supports, which is hereafter referred to as OcCaMix for short. It not only captures the most discriminative regions, but also effectively preserves the contour details of the objects. Moreover, it enables the search of natural object parts of different sizes. Extensive experiments on a large number of benchmark datasets show that OcCaMix significantly outperforms state-of-the-art CutMix based data augmentation methods in classification tasks. The source codes and trained models are available at https://github.com/DanielaPlusPlus/OcCaMix.}
}